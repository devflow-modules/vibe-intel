import * as path from "path";
import { fileURLToPath } from "url";
import dotenv from "dotenv";
import OpenAI from "openai";
import type { VibeAIRequest, VibeAIResponse } from "./types.js";

// =========================
// üå± Carrega vari√°veis de ambiente
// =========================
const __dirname = path.dirname(fileURLToPath(import.meta.url));
const envPath = path.resolve(__dirname, "../../../.env.local");
dotenv.config({ path: envPath });

const isTestEnv = process.env.NODE_ENV === "test";

const openAiKey = process.env.OPENAI_API_KEY;
if (!openAiKey && !isTestEnv) {
  console.error(`‚ùå OPENAI_API_KEY n√£o encontrada.
Verifique o arquivo .env.local na raiz (${envPath})`);
  process.exit(1);
}

function createMockClient() {
  return {
    chat: {
      completions: {
        create: async () => ({
          choices: [
            {
              message: {
                content: '{"mocked":true}'
              }
            }
          ]
        })
      }
    }
  };
}

// =========================
// ü§ñ Cliente OpenAI
// =========================
const client = isTestEnv
  ? (createMockClient() as unknown as OpenAI)
  : new OpenAI({
      apiKey: openAiKey,
    });

// =========================
// üß† Fun√ß√£o principal com tipagem gen√©rica
// =========================
/**
 * Executa uma chamada ao modelo OpenAI com tipagem segura.
 * Tenta parsear o retorno em JSON para tipo <T>, se poss√≠vel.
 */
export async function ai<T = unknown>(
  request: VibeAIRequest
): Promise<VibeAIResponse & { parsed?: T }> {
  const completion = await client.chat.completions.create({
    model: request.model ?? "gpt-4o-mini",
    messages: request.messages,
    temperature: request.temperature ?? 0.2,
    max_tokens: request.maxTokens ?? 2000,
    // ‚ö†Ô∏è N√£o enviar metadata (gera erro 400 se 'store' n√£o estiver ativo)
  });

  const content = completion.choices?.[0]?.message?.content ?? "";
  let parsed: T | undefined;

  try {
    parsed = JSON.parse(content) as T;
  } catch {
    // conte√∫do n√£o √© JSON ‚Äî ignora
  }

  return {
    raw: completion,
    content,
    parsed,
  };
}
